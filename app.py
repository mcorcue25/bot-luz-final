import streamlit as st
import pandas as pd
import os
import matplotlib.pyplot as plt
import seaborn as sns
from langchain_google_genai import ChatGoogleGenerativeAI
from obtener_datos import descargar_datos_streamlit

# --- CONFIGURACI√ìN DE P√ÅGINA ---
st.set_page_config(page_title="Bot Luz ‚ö°", page_icon="‚ö°", layout="centered")
st.title("‚ö° Asistente del Mercado El√©ctrico")

# --- BARRA LATERAL ---
with st.sidebar:
    if st.button("üîÑ Actualizar Datos ESIOS"):
        descargar_datos_streamlit()
        st.cache_data.clear()
    st.info("üí° Consejo: Pregunta por precios m√°ximos, m√≠nimos o medias.")

# --- CARGAR DATOS ---
@st.cache_data
def cargar_datos():
    archivo = "datos_luz.csv"
    if not os.path.exists(archivo):
        return None
    try:
        df = pd.read_csv(archivo)
        df['fecha_hora'] = pd.to_datetime(df['fecha_hora'])
        return df
    except Exception:
        return None

# --- NUESTRO PROPIO MOTOR DE IA (El "Mini-PandasAI") ---
class AgenteLuz:
    def __init__(self, df, api_key):
        self.df = df
        self.llm = ChatGoogleGenerativeAI(
            model="gemini-pro", # Usamos el modelo estable
            google_api_key=api_key,
            temperature=0
        )

    def preguntar(self, pregunta):
        # 1. Preparamos la informaci√≥n para Gemini
        dtypes = str(self.df.dtypes)
        columns = str(list(self.df.columns))
        head = str(self.df.head(3).to_markdown())
        
        # 2. El Prompt Maestro (Instrucciones precisas)
        prompt = f"""
        Act√∫a como un analista de datos experto en Python y Pandas.
        Tienes un dataframe cargado en la variable 'df'.
        
        ESTRUCTURA DEL DATAFRAME:
        Columnas: {columns}
        Tipos: \n{dtypes}
        Ejemplo de datos: \n{head}
        
        PREGUNTA DEL USUARIO: "{pregunta}"
        
        TU TAREA:
        1. Genera c√≥digo Python ejecutable para responder a la pregunta.
        2. Usa la variable 'df' directamente.
        3. Si la respuesta es un dato (n√∫mero, texto), gu√°rdalo en la variable 'resultado'.
        4. Si el usuario pide un GR√ÅFICO:
           - Crea el gr√°fico con matplotlib/seaborn.
           - Gu√°rdalo en un objeto 'fig' (ej: fig = plt.gcf()).
           - Asigna resultado = "GR√ÅFICO_GENERADO"
        5. IMPORTANTE: NO uses print().
        6. IMPORTANTE: Devuelve SOLO el c√≥digo, sin comillas de markdown (```python).
        """
        
        # 3. Llamamos a Gemini
        try:
            codigo_generado = self.llm.invoke(prompt).content
            
            # Limpieza b√°sica por si Gemini pone comillas
            codigo_generado = codigo_generado.replace("```python", "").replace("```", "").strip()
            
            # 4. EJECUCI√ìN DEL C√ìDIGO (La Magia)
            # Creamos un entorno seguro con las librer√≠as necesarias
            local_vars = {
                "df": self.df, 
                "pd": pd, 
                "plt": plt, 
                "sns": sns,
                "resultado": None,
                "fig": None
            }
            
            # Ejecutamos el c√≥digo generado por la IA
            exec(codigo_generado, {}, local_vars)
            
            # 5. Recuperamos lo que la IA calcul√≥
            resultado = local_vars.get("resultado")
            figura = local_vars.get("fig")
            
            if resultado == "GR√ÅFICO_GENERADO" and figura:
                return "IMG", figura
            elif resultado is not None:
                return "TXT", str(resultado)
            else:
                return "ERR", "La IA ejecut√≥ el c√≥digo pero no guard√≥ nada en la variable 'resultado'."
                
        except Exception as e:
            return "ERR", f"Error de ejecuci√≥n: {str(e)}\n\nC√≥digo que fall√≥:\n{codigo_generado}"

# --- INTERFAZ PRINCIPAL ---
df = cargar_datos()

if df is None:
    st.warning("‚ö†Ô∏è No hay datos. Pulsa 'Actualizar Datos' en la izquierda.")
else:
    # Mostramos resumen r√°pido
    st.success(f"‚úÖ Datos cargados: {len(df)} registros disponibles.")

    # Inicializamos chat
    if "messages" not in st.session_state:
        st.session_state.messages = []

    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            if message.get("type") == "image":
                st.pyplot(message["content"])
            else:
                st.markdown(message["content"])

    # Input del usuario
    if prompt := st.chat_input("Ej: ¬øCu√°l es el precio medio de hoy?"):
        # Guardar mensaje usuario
        st.session_state.messages.append({"role": "user", "content": prompt, "type": "text"})
        with st.chat_message("user"):
            st.markdown(prompt)

        # Respuesta del Asistente
        with st.chat_message("assistant"):
            with st.spinner("Analizando datos..."):
                try:
                    # Instanciamos nuestro Agente Casero
                    api_key = st.secrets["GEMINI_API_KEY"]
                    bot = AgenteLuz(df, api_key)
                    
                    # Preguntamos
                    tipo, respuesta = bot.preguntar(prompt)
                    
                    if tipo == "IMG":
                        st.pyplot(respuesta)
                        st.session_state.messages.append({"role": "assistant", "content": respuesta, "type": "image"})
                    elif tipo == "TXT":
                        st.write(respuesta)
                        st.session_state.messages.append({"role": "assistant", "content": respuesta, "type": "text"})
                    else: # Error
                        st.error(respuesta)
                        
                except Exception as e:
                    st.error(f"‚ùå Error general: {e}")
